{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tqdm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/cv-other-train/sample-069205.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/cv-valid-train/sample-063134.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/cv-other-train/sample-080873.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/cv-other-train/sample-105595.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/cv-valid-train/sample-144613.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                filename  gender\n",
       "0  data/cv-other-train/sample-069205.npy  female\n",
       "1  data/cv-valid-train/sample-063134.npy  female\n",
       "2  data/cv-other-train/sample-080873.npy  female\n",
       "3  data/cv-other-train/sample-105595.npy  female\n",
       "4  data/cv-valid-train/sample-144613.npy  female"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"balanced-all.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 66938\n",
      "Total male samples: 33469\n",
      "Total female samples: 33469\n"
     ]
    }
   ],
   "source": [
    "# get total samples\n",
    "n_samples = len(df)\n",
    "# get total male samples\n",
    "n_male_samples = len(df[df['gender'] == 'male'])\n",
    "# get total female samples\n",
    "n_female_samples = len(df[df['gender'] == 'female'])\n",
    "print(\"Total samples:\", n_samples)\n",
    "print(\"Total male samples:\", n_male_samples)\n",
    "print(\"Total female samples:\", n_female_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2int = {\n",
    "    \"male\": 1,\n",
    "    \"female\": 0\n",
    "}\n",
    "\n",
    "def load_data(vector_length=128):\n",
    "    \"\"\"A function to load gender recognition dataset from `data` folder\n",
    "    After the second run, this will load from results/features.npy and results/labels.npy files\n",
    "    as it is much faster!\"\"\"\n",
    "    # make sure results folder exists\n",
    "    if not os.path.isdir(\"results\"):\n",
    "        os.mkdir(\"results\")\n",
    "    # if features & labels already loaded individually and bundled, load them from there instead\n",
    "    if os.path.isfile(\"results/features.npy\") and os.path.isfile(\"results/labels.npy\"):\n",
    "        X = np.load(\"results/features.npy\")\n",
    "        y = np.load(\"results/labels.npy\")\n",
    "        return X, y\n",
    "    # read dataframe\n",
    "    df = pd.read_csv(\"balanced-all.csv\")\n",
    "    # get total samples\n",
    "    n_samples = len(df)\n",
    "    # get total male samples\n",
    "    n_male_samples = len(df[df['gender'] == 'male'])\n",
    "    # get total female samples\n",
    "    n_female_samples = len(df[df['gender'] == 'female'])\n",
    "    print(\"Total samples:\", n_samples)\n",
    "    print(\"Total male samples:\", n_male_samples)\n",
    "    print(\"Total female samples:\", n_female_samples)\n",
    "    # initialize an empty array for all audio features\n",
    "    X = np.zeros((n_samples, vector_length))\n",
    "    # initialize an empty array for all audio labels (1 for male and 0 for female)\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    for i, (filename, gender) in tqdm.tqdm(enumerate(zip(df['filename'], df['gender'])), \"Loading data\", total=n_samples):\n",
    "        features = np.load(filename)\n",
    "        X[i] = features\n",
    "        y[i] = label2int[gender]\n",
    "    # save the audio features and labels into files\n",
    "    # so we won't load each one of them next run\n",
    "    np.save(\"results/features\", X)\n",
    "    np.save(\"results/labels\", y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.1, valid_size=0.1):\n",
    "    # split training set and testing set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=7)\n",
    "    # split training set and validation set\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=valid_size, random_state=7)\n",
    "    # return a dictionary of values\n",
    "    return {\n",
    "        \"X_train\": X_train,\n",
    "        \"X_valid\": X_valid,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_valid\": y_valid,\n",
    "        \"y_test\": y_test\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "X, y = load_data()\n",
    "# split the data into training, validation and testing sets\n",
    "data = split_data(X, y, test_size=0.1, valid_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "def create_mlp_model(vector_length=128):\n",
    "    \"\"\"5 hidden dense layers from 256 units to 64, not the best model.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape=(vector_length,)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    # one output neuron with sigmoid activation function, 0 means female, 1 means male\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    # using binary crossentropy as it's male/female classification (binary)\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
    "    # print summary of the model\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 156,545\n",
      "Trainable params: 156,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# construct the model\n",
    "model = create_mlp_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "848/848 [==============================] - 6s 5ms/step - loss: 0.5631 - accuracy: 0.7574 - val_loss: 0.3709 - val_accuracy: 0.8500\n",
      "Epoch 2/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.4171 - accuracy: 0.8328 - val_loss: 0.3418 - val_accuracy: 0.8685\n",
      "Epoch 3/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3785 - accuracy: 0.8520 - val_loss: 0.3278 - val_accuracy: 0.8732\n",
      "Epoch 4/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3615 - accuracy: 0.8588 - val_loss: 0.3002 - val_accuracy: 0.8833\n",
      "Epoch 5/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3480 - accuracy: 0.8677 - val_loss: 0.2865 - val_accuracy: 0.8863\n",
      "Epoch 6/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3327 - accuracy: 0.8732 - val_loss: 0.2790 - val_accuracy: 0.8910\n",
      "Epoch 7/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3272 - accuracy: 0.8760 - val_loss: 0.2825 - val_accuracy: 0.8885\n",
      "Epoch 8/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3219 - accuracy: 0.8786 - val_loss: 0.2696 - val_accuracy: 0.8953\n",
      "Epoch 9/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3144 - accuracy: 0.8806 - val_loss: 0.2712 - val_accuracy: 0.8964\n",
      "Epoch 10/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3063 - accuracy: 0.8852 - val_loss: 0.2663 - val_accuracy: 0.8958\n",
      "Epoch 11/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.3018 - accuracy: 0.8855 - val_loss: 0.2526 - val_accuracy: 0.9004\n",
      "Epoch 12/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2957 - accuracy: 0.8888 - val_loss: 0.2613 - val_accuracy: 0.8998\n",
      "Epoch 13/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2910 - accuracy: 0.8913 - val_loss: 0.2630 - val_accuracy: 0.8991\n",
      "Epoch 14/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2960 - accuracy: 0.8894 - val_loss: 0.2479 - val_accuracy: 0.9044\n",
      "Epoch 15/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2852 - accuracy: 0.8910 - val_loss: 0.2560 - val_accuracy: 0.8981\n",
      "Epoch 16/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2899 - accuracy: 0.8916 - val_loss: 0.2567 - val_accuracy: 0.9039\n",
      "Epoch 17/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2822 - accuracy: 0.8939 - val_loss: 0.2495 - val_accuracy: 0.9105\n",
      "Epoch 18/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2807 - accuracy: 0.8939 - val_loss: 0.2504 - val_accuracy: 0.9021\n",
      "Epoch 19/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2768 - accuracy: 0.8958 - val_loss: 0.2390 - val_accuracy: 0.9095\n",
      "Epoch 20/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2738 - accuracy: 0.8974 - val_loss: 0.2658 - val_accuracy: 0.9042\n",
      "Epoch 21/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2752 - accuracy: 0.8966 - val_loss: 0.2391 - val_accuracy: 0.9092\n",
      "Epoch 22/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2773 - accuracy: 0.8959 - val_loss: 0.2386 - val_accuracy: 0.9124\n",
      "Epoch 23/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2703 - accuracy: 0.8985 - val_loss: 0.2403 - val_accuracy: 0.9072\n",
      "Epoch 24/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2681 - accuracy: 0.9011 - val_loss: 0.2311 - val_accuracy: 0.9182\n",
      "Epoch 25/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2682 - accuracy: 0.9013 - val_loss: 0.2352 - val_accuracy: 0.9115\n",
      "Epoch 26/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2662 - accuracy: 0.9012 - val_loss: 0.2336 - val_accuracy: 0.9132\n",
      "Epoch 27/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2688 - accuracy: 0.9003 - val_loss: 0.2374 - val_accuracy: 0.9090\n",
      "Epoch 28/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.2684 - accuracy: 0.9016 - val_loss: 0.2322 - val_accuracy: 0.9117\n",
      "Epoch 29/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2724 - accuracy: 0.8999 - val_loss: 0.2356 - val_accuracy: 0.9124\n",
      "Epoch 30/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2606 - accuracy: 0.9023 - val_loss: 0.2294 - val_accuracy: 0.9170\n",
      "Epoch 31/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2599 - accuracy: 0.9044 - val_loss: 0.2327 - val_accuracy: 0.9178\n",
      "Epoch 32/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2603 - accuracy: 0.9032 - val_loss: 0.2360 - val_accuracy: 0.9150\n",
      "Epoch 33/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2625 - accuracy: 0.9028 - val_loss: 0.2345 - val_accuracy: 0.9122\n",
      "Epoch 34/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2562 - accuracy: 0.9046 - val_loss: 0.2408 - val_accuracy: 0.9144\n",
      "Epoch 35/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2567 - accuracy: 0.9039 - val_loss: 0.2279 - val_accuracy: 0.9154\n",
      "Epoch 36/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2572 - accuracy: 0.9037 - val_loss: 0.2303 - val_accuracy: 0.9144\n",
      "Epoch 37/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2574 - accuracy: 0.9044 - val_loss: 0.2223 - val_accuracy: 0.9147\n",
      "Epoch 38/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2551 - accuracy: 0.9064 - val_loss: 0.2194 - val_accuracy: 0.9213\n",
      "Epoch 39/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2586 - accuracy: 0.9048 - val_loss: 0.2300 - val_accuracy: 0.9159\n",
      "Epoch 40/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2523 - accuracy: 0.9071 - val_loss: 0.2196 - val_accuracy: 0.9145\n",
      "Epoch 41/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2468 - accuracy: 0.9089 - val_loss: 0.2147 - val_accuracy: 0.9215\n",
      "Epoch 42/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2551 - accuracy: 0.9064 - val_loss: 0.2268 - val_accuracy: 0.9132\n",
      "Epoch 43/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2527 - accuracy: 0.9076 - val_loss: 0.2346 - val_accuracy: 0.9144\n",
      "Epoch 44/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2564 - accuracy: 0.9049 - val_loss: 0.2222 - val_accuracy: 0.9147\n",
      "Epoch 45/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2461 - accuracy: 0.9089 - val_loss: 0.2229 - val_accuracy: 0.9168\n",
      "Epoch 46/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2559 - accuracy: 0.9066 - val_loss: 0.2166 - val_accuracy: 0.9203\n",
      "Epoch 47/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2456 - accuracy: 0.9099 - val_loss: 0.2166 - val_accuracy: 0.9200\n",
      "Epoch 48/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2463 - accuracy: 0.9098 - val_loss: 0.2195 - val_accuracy: 0.9213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22bb66e3460>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use tensorboard to view metrics\n",
    "mlp_tensorboard = TensorBoard(log_dir='logs/mlp_logs/')\n",
    "# define early stopping to stop training after 7 epochs of not improving\n",
    "early_stopping = EarlyStopping(mode=\"min\", patience=7, restore_best_weights=True)\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "# train the model using the training set and validating using validation set\n",
    "model.fit(data[\"X_train\"], data[\"y_train\"], epochs=epochs, batch_size=batch_size, validation_data=(data[\"X_valid\"], data[\"y_valid\"]),\n",
    "          callbacks=[mlp_tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to a file\n",
    "model.save(\"results/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "\n",
    "def create_cnn_model(vector_length=128):\n",
    "    \"\"\"Simple 1D CNN with Conv1D and MaxPooling1D layers.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(vector_length, 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(128, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
    "    \n",
    "    # Print the model summary\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 126, 64)           256       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 63, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 63, 64)            0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 61, 128)           24704     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 30, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 30, 128)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3840)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               491648    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 524,929\n",
      "Trainable params: 524,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# construct the model\n",
    "cnn_model = create_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "848/848 [==============================] - 8s 6ms/step - loss: 0.4143 - accuracy: 0.8213 - val_loss: 0.2781 - val_accuracy: 0.8939\n",
      "Epoch 2/100\n",
      "848/848 [==============================] - 5s 5ms/step - loss: 0.2927 - accuracy: 0.8850 - val_loss: 0.2253 - val_accuracy: 0.9109\n",
      "Epoch 3/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2667 - accuracy: 0.8977 - val_loss: 0.2142 - val_accuracy: 0.9178\n",
      "Epoch 4/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2503 - accuracy: 0.9028 - val_loss: 0.1979 - val_accuracy: 0.9230\n",
      "Epoch 5/100\n",
      "848/848 [==============================] - 5s 5ms/step - loss: 0.2344 - accuracy: 0.9103 - val_loss: 0.1894 - val_accuracy: 0.9298\n",
      "Epoch 6/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2223 - accuracy: 0.9142 - val_loss: 0.1982 - val_accuracy: 0.9263\n",
      "Epoch 7/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2145 - accuracy: 0.9184 - val_loss: 0.1772 - val_accuracy: 0.9346\n",
      "Epoch 8/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.2065 - accuracy: 0.9216 - val_loss: 0.1742 - val_accuracy: 0.9359\n",
      "Epoch 9/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.1998 - accuracy: 0.9249 - val_loss: 0.1696 - val_accuracy: 0.9368\n",
      "Epoch 10/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.1940 - accuracy: 0.9263 - val_loss: 0.1756 - val_accuracy: 0.9373\n",
      "Epoch 11/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.1900 - accuracy: 0.9294 - val_loss: 0.1653 - val_accuracy: 0.9404\n",
      "Epoch 12/100\n",
      "848/848 [==============================] - 5s 5ms/step - loss: 0.1843 - accuracy: 0.9322 - val_loss: 0.1616 - val_accuracy: 0.9429\n",
      "Epoch 13/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.1802 - accuracy: 0.9326 - val_loss: 0.1594 - val_accuracy: 0.9447\n",
      "Epoch 14/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.1751 - accuracy: 0.9335 - val_loss: 0.1572 - val_accuracy: 0.9434\n",
      "Epoch 15/100\n",
      "848/848 [==============================] - 4s 4ms/step - loss: 0.1735 - accuracy: 0.9361 - val_loss: 0.1543 - val_accuracy: 0.9456\n",
      "Epoch 16/100\n",
      "848/848 [==============================] - 4s 5ms/step - loss: 0.1725 - accuracy: 0.9352 - val_loss: 0.1525 - val_accuracy: 0.9454\n",
      "Epoch 17/100\n",
      "848/848 [==============================] - 5s 5ms/step - loss: 0.1641 - accuracy: 0.9385 - val_loss: 0.1493 - val_accuracy: 0.9461\n",
      "Epoch 18/100\n",
      "848/848 [==============================] - 5s 6ms/step - loss: 0.1636 - accuracy: 0.9393 - val_loss: 0.1507 - val_accuracy: 0.9447\n",
      "Epoch 19/100\n",
      "848/848 [==============================] - 5s 5ms/step - loss: 0.1590 - accuracy: 0.9404 - val_loss: 0.1457 - val_accuracy: 0.9480\n",
      "Epoch 20/100\n",
      "848/848 [==============================] - 5s 5ms/step - loss: 0.1553 - accuracy: 0.9420 - val_loss: 0.1471 - val_accuracy: 0.9489\n",
      "Epoch 21/100\n",
      "848/848 [==============================] - 5s 5ms/step - loss: 0.1540 - accuracy: 0.9433 - val_loss: 0.1498 - val_accuracy: 0.9490\n",
      "Epoch 22/100\n",
      "848/848 [==============================] - 5s 5ms/step - loss: 0.1517 - accuracy: 0.9429 - val_loss: 0.1504 - val_accuracy: 0.9461\n",
      "Epoch 23/100\n",
      "848/848 [==============================] - 5s 5ms/step - loss: 0.1483 - accuracy: 0.9431 - val_loss: 0.1456 - val_accuracy: 0.9482\n",
      "Epoch 24/100\n",
      "848/848 [==============================] - 5s 5ms/step - loss: 0.1455 - accuracy: 0.9460 - val_loss: 0.1406 - val_accuracy: 0.9509\n",
      "Epoch 25/100\n",
      "848/848 [==============================] - 5s 5ms/step - loss: 0.1442 - accuracy: 0.9466 - val_loss: 0.1358 - val_accuracy: 0.9539\n",
      "Epoch 26/100\n",
      "848/848 [==============================] - 5s 5ms/step - loss: 0.1417 - accuracy: 0.9467 - val_loss: 0.1392 - val_accuracy: 0.9515\n",
      "Epoch 27/100\n",
      "848/848 [==============================] - 5s 6ms/step - loss: 0.1398 - accuracy: 0.9479 - val_loss: 0.1454 - val_accuracy: 0.9500\n",
      "Epoch 28/100\n",
      "848/848 [==============================] - 5s 6ms/step - loss: 0.1419 - accuracy: 0.9472 - val_loss: 0.1484 - val_accuracy: 0.9480\n",
      "Epoch 29/100\n",
      "848/848 [==============================] - 5s 6ms/step - loss: 0.1376 - accuracy: 0.9487 - val_loss: 0.1430 - val_accuracy: 0.9512\n",
      "Epoch 30/100\n",
      "848/848 [==============================] - 5s 5ms/step - loss: 0.1364 - accuracy: 0.9503 - val_loss: 0.1416 - val_accuracy: 0.9517\n",
      "Epoch 31/100\n",
      "848/848 [==============================] - 5s 5ms/step - loss: 0.1338 - accuracy: 0.9507 - val_loss: 0.1373 - val_accuracy: 0.9555\n",
      "Epoch 32/100\n",
      "848/848 [==============================] - 5s 5ms/step - loss: 0.1304 - accuracy: 0.9519 - val_loss: 0.1368 - val_accuracy: 0.9552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22b99aea7c0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use tensorboard to view metrics\n",
    "cnn_tensorboard = TensorBoard(log_dir='logs/cnn_logs/')\n",
    "# define early stopping to stop training after 7 epochs of not improving\n",
    "early_stopping = EarlyStopping(mode=\"min\", patience=7, restore_best_weights=True)\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "# train the model using the training set and validating using validation set\n",
    "cnn_model.fit(data[\"X_train\"], data[\"y_train\"], epochs=epochs, batch_size=batch_size, validation_data=(data[\"X_valid\"], data[\"y_valid\"]),\n",
    "          callbacks=[cnn_tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "\n",
    "def create_rnn_model(vector_length=128):\n",
    "    \"\"\"Simple RNN model using SimpleRNN layers.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(128, input_shape=(vector_length, 1), return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(SimpleRNN(64, return_sequences=False))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # Dense layer\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
    "    \n",
    "    # Print the model summary\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 128, 128)          16640     \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 128, 128)          0         \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 64)                12352     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,217\n",
      "Trainable params: 33,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# construct the model\n",
    "rnn_model = create_rnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "848/848 [==============================] - 187s 220ms/step - loss: 0.6982 - accuracy: 0.4986 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 2/100\n",
      "848/848 [==============================] - 196s 231ms/step - loss: 0.6935 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.5014\n",
      "Epoch 3/100\n",
      "848/848 [==============================] - 200s 235ms/step - loss: 0.6933 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5014\n",
      "Epoch 4/100\n",
      "848/848 [==============================] - 203s 240ms/step - loss: 0.6932 - accuracy: 0.4964 - val_loss: 0.6931 - val_accuracy: 0.5014\n",
      "Epoch 5/100\n",
      "848/848 [==============================] - 190s 224ms/step - loss: 0.6932 - accuracy: 0.4998 - val_loss: 0.6931 - val_accuracy: 0.5014\n",
      "Epoch 6/100\n",
      "848/848 [==============================] - 190s 225ms/step - loss: 0.6934 - accuracy: 0.5030 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 7/100\n",
      "848/848 [==============================] - 191s 225ms/step - loss: 0.6932 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5014\n",
      "Epoch 8/100\n",
      "848/848 [==============================] - 199s 234ms/step - loss: 0.6932 - accuracy: 0.5002 - val_loss: 0.6931 - val_accuracy: 0.5014\n",
      "Epoch 9/100\n",
      "848/848 [==============================] - 229s 270ms/step - loss: 0.6933 - accuracy: 0.5003 - val_loss: 0.6931 - val_accuracy: 0.5014\n",
      "Epoch 10/100\n",
      "848/848 [==============================] - 236s 278ms/step - loss: 0.6934 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 11/100\n",
      "848/848 [==============================] - 207s 244ms/step - loss: 0.6933 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.5014\n",
      "Epoch 12/100\n",
      "848/848 [==============================] - 195s 230ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6931 - val_accuracy: 0.5014\n",
      "Epoch 13/100\n",
      "848/848 [==============================] - 156s 184ms/step - loss: 0.6932 - accuracy: 0.5010 - val_loss: 0.6931 - val_accuracy: 0.5014\n",
      "Epoch 14/100\n",
      "210/848 [======>.......................] - ETA: 2:17 - loss: 0.6932 - accuracy: 0.5007"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# train the model using the training set and validating using validation set\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mrnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX_valid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_valid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mrnn_tensorboard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\xinye\\miniconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\xinye\\miniconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\xinye\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\xinye\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\xinye\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\xinye\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\xinye\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\xinye\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\xinye\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# use tensorboard to view metrics\n",
    "rnn_tensorboard = TensorBoard(log_dir='logs/rnn_logs')\n",
    "# define early stopping to stop training after 7 epochs of not improving\n",
    "early_stopping = EarlyStopping(mode=\"min\", patience=7, restore_best_weights=True)\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "# train the model using the training set and validating using validation set\n",
    "rnn_model.fit(data[\"X_train\"], data[\"y_train\"], epochs=epochs, batch_size=batch_size, validation_data=(data[\"X_valid\"], data[\"y_valid\"]),\n",
    "          callbacks=[rnn_tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MultiHeadAttention, LayerNormalization, Add, Dense, Dropout, Input, Reshape, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "def create_transformer_model(vector_length=128, num_heads=4):\n",
    "    \"\"\"Simple Transformer-based model.\"\"\"\n",
    "    \n",
    "    # Define the input layer\n",
    "    input_layer = Input(shape=(vector_length,))\n",
    "    \n",
    "    # Transform the input to match the expected dimension for MultiHeadAttention\n",
    "    dense_input = Dense(vector_length)(input_layer)\n",
    "    reshaped_input = Reshape((vector_length, 1))(dense_input)  # Reshape to (vector_length, 1)\n",
    "    \n",
    "    # Self-attention layer\n",
    "    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=vector_length)(reshaped_input, reshaped_input)\n",
    "    attention_output = Flatten()(attention_output)  # Flatten back for dense layers\n",
    "    attention_output = Dense(vector_length)(attention_output)  # Ensure the output shape matches the input layer\n",
    "    \n",
    "    # Combine the original input with the attention output\n",
    "    combined_output = Add()([dense_input, attention_output])\n",
    "    combined_output = LayerNormalization()(combined_output)\n",
    "    \n",
    "    # Dense layer\n",
    "    dense_output = Dense(64, activation=\"relu\")(combined_output)\n",
    "    dense_output = Dropout(0.3)(dense_output)\n",
    "    \n",
    "    # Output layer\n",
    "    output = Dense(1, activation=\"sigmoid\")(dense_output)\n",
    "    \n",
    "    # Compile the model\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
    "    \n",
    "    # Print the model summary\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 128)          16512       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 128, 1)       0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 128, 1)      3585        ['reshape[0][0]',                \n",
      " dAttention)                                                      'reshape[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 128)          0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 128)          16512       ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 128)          0           ['dense_17[0][0]',               \n",
      "                                                                  'dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 128)         256         ['add[0][0]']                    \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 64)           8256        ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 64)           0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 1)            65          ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 45,186\n",
      "Trainable params: 45,186\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# construct the model\n",
    "t_model = create_transformer_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "848/848 [==============================] - 8s 9ms/step - loss: 0.3587 - accuracy: 0.8458 - val_loss: 0.2883 - val_accuracy: 0.8823\n",
      "Epoch 2/100\n",
      "848/848 [==============================] - 7s 9ms/step - loss: 0.2982 - accuracy: 0.8791 - val_loss: 0.2606 - val_accuracy: 0.8959\n",
      "Epoch 3/100\n",
      "848/848 [==============================] - 7s 9ms/step - loss: 0.2785 - accuracy: 0.8890 - val_loss: 0.2646 - val_accuracy: 0.8939\n",
      "Epoch 4/100\n",
      "848/848 [==============================] - 7s 9ms/step - loss: 0.2653 - accuracy: 0.8946 - val_loss: 0.2430 - val_accuracy: 0.9054\n",
      "Epoch 5/100\n",
      "848/848 [==============================] - 7s 9ms/step - loss: 0.2566 - accuracy: 0.8980 - val_loss: 0.2433 - val_accuracy: 0.9041\n",
      "Epoch 6/100\n",
      "848/848 [==============================] - 7s 9ms/step - loss: 0.2489 - accuracy: 0.9025 - val_loss: 0.2362 - val_accuracy: 0.9109\n",
      "Epoch 7/100\n",
      "848/848 [==============================] - 7s 9ms/step - loss: 0.2433 - accuracy: 0.9056 - val_loss: 0.2453 - val_accuracy: 0.9041\n",
      "Epoch 8/100\n",
      "848/848 [==============================] - 7s 9ms/step - loss: 0.2359 - accuracy: 0.9087 - val_loss: 0.2296 - val_accuracy: 0.9135\n",
      "Epoch 9/100\n",
      "848/848 [==============================] - 7s 8ms/step - loss: 0.2286 - accuracy: 0.9117 - val_loss: 0.2275 - val_accuracy: 0.9139\n",
      "Epoch 10/100\n",
      "848/848 [==============================] - 7s 8ms/step - loss: 0.2262 - accuracy: 0.9134 - val_loss: 0.2266 - val_accuracy: 0.9135\n",
      "Epoch 11/100\n",
      "848/848 [==============================] - 7s 8ms/step - loss: 0.2216 - accuracy: 0.9136 - val_loss: 0.2364 - val_accuracy: 0.9085\n",
      "Epoch 12/100\n",
      "848/848 [==============================] - 7s 8ms/step - loss: 0.2184 - accuracy: 0.9147 - val_loss: 0.2238 - val_accuracy: 0.9185\n",
      "Epoch 13/100\n",
      "848/848 [==============================] - 7s 9ms/step - loss: 0.2144 - accuracy: 0.9160 - val_loss: 0.2226 - val_accuracy: 0.9172\n",
      "Epoch 14/100\n",
      "848/848 [==============================] - 7s 9ms/step - loss: 0.2115 - accuracy: 0.9191 - val_loss: 0.2311 - val_accuracy: 0.9130\n",
      "Epoch 15/100\n",
      "848/848 [==============================] - 7s 9ms/step - loss: 0.2061 - accuracy: 0.9200 - val_loss: 0.2179 - val_accuracy: 0.9197\n",
      "Epoch 16/100\n",
      "848/848 [==============================] - 7s 9ms/step - loss: 0.2044 - accuracy: 0.9208 - val_loss: 0.2193 - val_accuracy: 0.9187\n",
      "Epoch 17/100\n",
      "848/848 [==============================] - 7s 9ms/step - loss: 0.2026 - accuracy: 0.9207 - val_loss: 0.2172 - val_accuracy: 0.9230\n",
      "Epoch 18/100\n",
      "848/848 [==============================] - 7s 9ms/step - loss: 0.1995 - accuracy: 0.9231 - val_loss: 0.2181 - val_accuracy: 0.9187\n",
      "Epoch 19/100\n",
      "848/848 [==============================] - 7s 9ms/step - loss: 0.1949 - accuracy: 0.9238 - val_loss: 0.2151 - val_accuracy: 0.9227\n",
      "Epoch 20/100\n",
      "848/848 [==============================] - 7s 8ms/step - loss: 0.1935 - accuracy: 0.9263 - val_loss: 0.2173 - val_accuracy: 0.9235\n",
      "Epoch 21/100\n",
      "848/848 [==============================] - 7s 8ms/step - loss: 0.1902 - accuracy: 0.9257 - val_loss: 0.2195 - val_accuracy: 0.9210\n",
      "Epoch 22/100\n",
      "848/848 [==============================] - 7s 9ms/step - loss: 0.1907 - accuracy: 0.9264 - val_loss: 0.2198 - val_accuracy: 0.9172\n",
      "Epoch 23/100\n",
      "848/848 [==============================] - 8s 9ms/step - loss: 0.1871 - accuracy: 0.9279 - val_loss: 0.2151 - val_accuracy: 0.9235\n",
      "Epoch 24/100\n",
      "848/848 [==============================] - 7s 9ms/step - loss: 0.1850 - accuracy: 0.9282 - val_loss: 0.2270 - val_accuracy: 0.9213\n",
      "Epoch 25/100\n",
      "848/848 [==============================] - 7s 8ms/step - loss: 0.1822 - accuracy: 0.9297 - val_loss: 0.2162 - val_accuracy: 0.9222\n",
      "Epoch 26/100\n",
      "848/848 [==============================] - 7s 8ms/step - loss: 0.1816 - accuracy: 0.9297 - val_loss: 0.2242 - val_accuracy: 0.9187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22dc4a9f370>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use tensorboard to view metrics\n",
    "transformer_tensorboard = TensorBoard(log_dir='logs/t_logs')\n",
    "# define early stopping to stop training after 7 epochs of not improving\n",
    "early_stopping = EarlyStopping(mode=\"min\", patience=7, restore_best_weights=True)\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "# train the model using the training set and validating using validation set\n",
    "t_model.fit(data[\"X_train\"], data[\"y_train\"], epochs=epochs, batch_size=batch_size, validation_data=(data[\"X_valid\"], data[\"y_valid\"]),\n",
    "          callbacks=[transformer_tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard --logdir=\"logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the multilayered perceptron model using 6694 samples...\n",
      "Loss: 0.2233\n",
      "Accuracy: 92.01%\n"
     ]
    }
   ],
   "source": [
    "# evaluating the multilayered perceptron model using the testing set\n",
    "print(f\"Evaluating the multilayered perceptron model using {len(data['X_test'])} samples...\")\n",
    "loss, accuracy = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "print(f\"Loss: {loss:.4f}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the cnn model using 6694 samples...\n",
      "Loss: 0.1261\n",
      "Accuracy: 95.31%\n"
     ]
    }
   ],
   "source": [
    "# evaluating the cnn model using the testing set\n",
    "print(f\"Evaluating the cnn model using {len(data['X_test'])} samples...\")\n",
    "loss, accuracy = cnn_model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "print(f\"Loss: {loss:.4f}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the rnn model using 6694 samples...\n",
      "Loss: 0.6840\n",
      "Accuracy: 53.20%\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model using the testing set\n",
    "print(f\"Evaluating the rnn model using {len(data['X_test'])} samples...\")\n",
    "loss, accuracy = rnn_model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "print(f\"Loss: {loss:.4f}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the transformer model using 6694 samples...\n",
      "Loss: 0.2122\n",
      "Accuracy: 92.25%\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model using the testing set\n",
    "print(f\"Evaluating the transformer model using {len(data['X_test'])} samples...\")\n",
    "loss, accuracy = t_model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "print(f\"Loss: {loss:.4f}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to a file\n",
    "cnn_model.save(\"results/cnn_model.h5\")\n",
    "# save the model to a file\n",
    "rnn_model.save(\"results/rnn_model.h5\")\n",
    "# save the model to a file\n",
    "t_model.save(\"results/t_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# extracts voice features from a .wav file\n",
    "\n",
    "def extract_feature(file_name, **kwargs):\n",
    "    \"\"\"\n",
    "    Extract feature from audio file `file_name`\n",
    "        Features supported:\n",
    "            - MFCC (mfcc)\n",
    "            - Chroma (chroma)\n",
    "            - MEL Spectrogram Frequency (mel)\n",
    "            - Contrast (contrast)\n",
    "            - Tonnetz (tonnetz)\n",
    "        e.g:\n",
    "        `features = extract_feature(path, mel=True, mfcc=True)`\n",
    "    \"\"\"\n",
    "    mfcc = kwargs.get(\"mfcc\")\n",
    "    chroma = kwargs.get(\"chroma\")\n",
    "    mel = kwargs.get(\"mel\")\n",
    "    contrast = kwargs.get(\"contrast\")\n",
    "    tonnetz = kwargs.get(\"tonnetz\")\n",
    "    X, sample_rate = librosa.core.load(file_name)\n",
    "    if chroma or contrast:\n",
    "        stft = np.abs(librosa.stft(X))\n",
    "    result = np.array([])\n",
    "    if mfcc:\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "        result = np.hstack((result, mfccs))\n",
    "    if chroma:\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, chroma))\n",
    "    if mel:\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=X, sr=sample_rate)\n",
    "        mel = np.mean(mel_spectrogram.T, axis=0)\n",
    "        result = np.hstack((result, mel))\n",
    "    if contrast:\n",
    "        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, contrast))\n",
    "    if tonnetz:\n",
    "        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, tonnetz))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_2 (SimpleRNN)    (None, 128, 128)          16640     \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 128, 128)          0         \n",
      "                                                                 \n",
      " simple_rnn_3 (SimpleRNN)    (None, 64)                12352     \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,217\n",
      "Trainable params: 33,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E7AAC1EC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "Result: male\n",
      "Probabilities::: Male: 51.02%    Female: 48.98%\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description=\"\"\"Gender recognition script, this will load the model you trained, \n",
    "                                    and perform inference on a sample you provide (either using your voice or a file)\"\"\")\n",
    "parser.add_argument(\"-f\", \"--file\", help=\"The path to the file, preferred to be in WAV format\")\n",
    "args = parser.parse_args()\n",
    "file = \"my_voice/testwav.wav\"\n",
    "# construct the model\n",
    "model = create_rnn_model()\n",
    "# load the saved/trained weights\n",
    "model.load_weights(\"results/rnn_model.h5\")\n",
    "if not file or not os.path.isfile(file):\n",
    "    # if file not provided, or it doesn't exist, use your voice\n",
    "    print(\"Please talk\")\n",
    "    # put the file name here\n",
    "    file = \"test.wav\"\n",
    "# extract features and reshape it\n",
    "features = extract_feature(file, mel=True).reshape(1, -1)\n",
    "# predict the gender!\n",
    "male_prob = model.predict(features)[0][0]\n",
    "female_prob = 1 - male_prob\n",
    "gender = \"male\" if male_prob > female_prob else \"female\"\n",
    "# show the result!\n",
    "print(\"Result:\", gender)\n",
    "print(f\"Probabilities::: Male: {male_prob*100:.2f}%    Female: {female_prob*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_79 (Dense)               (None, 128)          16512       ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 128, 1)       0           ['dense_79[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (MultiH  (None, 128, 1)      3585        ['reshape_4[0][0]',              \n",
      " eadAttention)                                                    'reshape_4[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)            (None, 128)          0           ['multi_head_attention_9[0][0]'] \n",
      "                                                                                                  \n",
      " dense_80 (Dense)               (None, 128)          16512       ['flatten_8[0][0]']              \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 128)          0           ['dense_79[0][0]',               \n",
      "                                                                  'dense_80[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 128)         256         ['add_4[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_81 (Dense)               (None, 64)           8256        ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_63 (Dropout)           (None, 64)           0           ['dense_81[0][0]']               \n",
      "                                                                                                  \n",
      " dense_82 (Dense)               (None, 1)            65          ['dropout_63[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 45,186\n",
      "Trainable params: 45,186\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# all models test on my voice and friend's voice\n",
    "model = create_transformer_model()\n",
    "# load the saved/trained weights\n",
    "model.load_weights(\"results/t_model.h5\")\n",
    "# extract features and reshape it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 105ms/step\n",
      "Result: male\n",
      "Probabilities::: Male: 96.30%    Female: 3.70%\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Result: female\n",
      "Probabilities::: Male: 29.35%    Female: 70.65%\n"
     ]
    }
   ],
   "source": [
    "male_file = \"my_voice/testwav.wav\"\n",
    "\n",
    "female_file = \"my_voice/female.wav\"\n",
    "\n",
    "features = extract_feature(male_file, mel=True).reshape(1, -1)\n",
    "# predict the gender!\n",
    "male_prob = model.predict(features)[0][0]\n",
    "female_prob = 1 - male_prob\n",
    "gender = \"male\" if male_prob > female_prob else \"female\"\n",
    "# show the result!\n",
    "print(\"Result:\", gender)\n",
    "print(f\"Probabilities::: Male: {male_prob*100:.2f}%    Female: {female_prob*100:.2f}%\")\n",
    "\n",
    "features = extract_feature(female_file, mel=True).reshape(1, -1)\n",
    "# predict the gender!\n",
    "male_prob = model.predict(features)[0][0]\n",
    "female_prob = 1 - male_prob\n",
    "gender = \"male\" if male_prob > female_prob else \"female\"\n",
    "# show the result!\n",
    "print(\"Result:\", gender)\n",
    "print(f\"Probabilities::: Male: {male_prob*100:.2f}%    Female: {female_prob*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
